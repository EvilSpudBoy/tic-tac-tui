{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TicTacTwo: Estimate Total Number of Possible Positions\n",
        "\n",
        "This notebook computes a combinatorial estimate for the TicTacTwo variant in this repo.\n",
        "\n",
        "Assumptions used:\n",
        "- Board is 5x5 (25 cells).\n",
        "- Each player can have at most 4 pieces on board.\n",
        "- Legal turn progression implies only these count pairs are reachable during play:\n",
        "  (0,0), (1,0), (1,1), (2,1), (2,2), (3,2), (3,3), (4,3), (4,4).\n",
        "- Active 3x3 window can be in 9 positions.\n",
        "- For (4,4), either side can be to move (because later turns are move/shift only).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from math import comb\n",
        "\n",
        "BOARD_CELLS = 25\n",
        "ACTIVE_WINDOW_POSITIONS = 9\n",
        "\n",
        "legal_count_pairs = [\n",
        "    (0, 0), (1, 0), (1, 1), (2, 1), (2, 2),\n",
        "    (3, 2), (3, 3), (4, 3), (4, 4),\n",
        "]\n",
        "\n",
        "def arrangements_for_counts(x_count: int, o_count: int) -> int:\n",
        "    return comb(BOARD_CELLS, x_count) * comb(BOARD_CELLS - x_count, o_count)\n",
        "\n",
        "board_only_legal = sum(arrangements_for_counts(x, o) for x, o in legal_count_pairs)\n",
        "positions_with_active = board_only_legal * ACTIVE_WINDOW_POSITIONS\n",
        "\n",
        "# Side-to-move is uniquely determined for all count pairs except (4,4),\n",
        "# where both players can be to move after placement phase.\n",
        "extra_turn_states_at_4_4 = arrangements_for_counts(4, 4) * ACTIVE_WINDOW_POSITIONS\n",
        "states_including_turn = positions_with_active + extra_turn_states_at_4_4\n",
        "\n",
        "# Looser upper bound: all (x,o) with 0<=x<=4 and 0<=o<=4, ignoring turn legality.\n",
        "board_only_unconstrained = sum(\n",
        "    arrangements_for_counts(x, o)\n",
        "    for x in range(5)\n",
        "    for o in range(5)\n",
        ")\n",
        "\n",
        "results = {\n",
        "    \"board_only_legal_count_pairs\": board_only_legal,\n",
        "    \"positions_with_active_window\": positions_with_active,\n",
        "    \"game_states_including_side_to_move\": states_including_turn,\n",
        "    \"board_only_unconstrained_upper_bound\": board_only_unconstrained,\n",
        "}\n",
        "results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpretation\n",
        "\n",
        "Key estimate to use for planning search/storage work:\n",
        "- `positions_with_active_window` = 870,223,284\n",
        "- `game_states_including_side_to_move` = 1,551,615,534\n",
        "\n",
        "These are combinatorial counts under rules-consistent piece totals, not the exact number of states reachable from the initial state after enforcing all dynamic constraints.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ceb69f4",
      "metadata": {},
      "source": [
        "## Reachable-Subset Bounds From Initial State\n",
        "\n",
        "This section adds empirical bounds for *actually reachable* states from the initial position.\n",
        "\n",
        "- Lower bound: exact unique states reached up to a fixed ply depth via forward expansion.\n",
        "- Upper bound: the combinatorial total from the previous section.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59c4a62d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import subprocess\n",
        "\n",
        "def run_node(js_code: str) -> str:\n",
        "    result = subprocess.run(\n",
        "        [\"node\", \"-e\", js_code],\n",
        "        check=True,\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "    )\n",
        "    return result.stdout.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aba1773b",
      "metadata": {},
      "outputs": [],
      "source": [
        "max_depth = 8\n",
        "\n",
        "depth_js = r\"\"\"\n",
        "const { createInitialState, getStateKey, getAvailableActions, applyAction, getOpponent, getWinner, isDraw } = require(\"./dist/game\");\n",
        "\n",
        "function depthCounts(maxDepth){\n",
        "  let layer = [{state:createInitialState(), player:\"X\"}];\n",
        "  const seen = new Set();\n",
        "  const rows = [];\n",
        "\n",
        "  for(let depth=0; depth<=maxDepth; depth++){\n",
        "    const layerMap = new Map();\n",
        "    for(const n of layer){\n",
        "      const k = getStateKey(n.state,n.player);\n",
        "      if(!layerMap.has(k)) layerMap.set(k,n);\n",
        "    }\n",
        "    layer = Array.from(layerMap.values());\n",
        "\n",
        "    for(const n of layer) seen.add(getStateKey(n.state,n.player));\n",
        "\n",
        "    let terminal = 0;\n",
        "    const nextMap = new Map();\n",
        "    if(depth < maxDepth){\n",
        "      for(const n of layer){\n",
        "        if(getWinner(n.state) || isDraw(n.state)) { terminal++; continue; }\n",
        "        const np = getOpponent(n.player);\n",
        "        for(const a of getAvailableActions(n.state,n.player)){\n",
        "          const ns = applyAction(n.state,a,n.player);\n",
        "          const nk = getStateKey(ns,np);\n",
        "          if(!nextMap.has(nk)) nextMap.set(nk,{state:ns,player:np});\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "\n",
        "    rows.push({\n",
        "      depth,\n",
        "      uniqueAtDepth: layer.length,\n",
        "      cumulativeUniqueToDepth: seen.size,\n",
        "      terminalAtDepth: terminal,\n",
        "      uniqueNextDepth: nextMap.size\n",
        "    });\n",
        "\n",
        "    layer = Array.from(nextMap.values());\n",
        "  }\n",
        "  return rows;\n",
        "}\n",
        "\n",
        "console.log(JSON.stringify(depthCounts(8)));\n",
        "\"\"\"\n",
        "\n",
        "rows = json.loads(run_node(depth_js))\n",
        "for r in rows:\n",
        "    print(r)\n",
        "\n",
        "lower_bound = rows[-1][\"cumulativeUniqueToDepth\"]\n",
        "upper_bound = 1551615534\n",
        "print()\n",
        "print({\n",
        "    \"reachable_lower_bound_from_depth_limited_expansion\": lower_bound,\n",
        "    \"reachable_upper_bound_combinatorial\": upper_bound,\n",
        "    \"fraction_of_upper_bound_covered_by_depth_prefix\": lower_bound / upper_bound,\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eb651c0",
      "metadata": {},
      "source": [
        "## Is X A Forced Win?\n",
        "\n",
        "Your observed repeated X wins can happen with deterministic tie-breaking and one fixed depth.\n",
        "\n",
        "To test whether that is actually a forced win, we run:\n",
        "- Deterministic self-play across depths.\n",
        "- Randomized tie-break self-play (choose randomly among equal-best moves).\n",
        "\n",
        "If O can win in these stronger probes, that is evidence against \"X forced win\" (though still not a full proof either way).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93dcb1ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "forced_win_js = r\"\"\"\n",
        "const { createInitialState, getWinner, isDraw, applyAction, getOpponent, getStateKey, getAvailableActions } = require(\"./dist/game\");\n",
        "const { getEngineEvaluations } = require(\"./dist/minimax\");\n",
        "const { runSelfPlayEpisode } = require(\"./dist/learning\");\n",
        "const { DEFAULT_EVALUATION_PLUGIN } = require(\"./dist/evaluation\");\n",
        "\n",
        "function deterministicSweep(maxDepth=6){\n",
        "  const rows=[];\n",
        "  for(let d=1; d<=maxDepth; d++){\n",
        "    const ep = runSelfPlayEpisode({depthLimit:d, maxTurns:200, evalPluginX:DEFAULT_EVALUATION_PLUGIN, evalPluginO:DEFAULT_EVALUATION_PLUGIN});\n",
        "    rows.push({depth:d, winner:ep.winner, turns:ep.turnCount, timeout:!!ep.terminatedByMaxTurns});\n",
        "  }\n",
        "  return rows;\n",
        "}\n",
        "\n",
        "function chooseWithRandomTiebreak(state, player, history, depthLimit){\n",
        "  const actions = getAvailableActions(state, player);\n",
        "  const multiPv = Math.max(1, actions.length);\n",
        "  const { evaluations } = getEngineEvaluations(state, player, history, depthLimit, multiPv, DEFAULT_EVALUATION_PLUGIN.evaluate);\n",
        "  if (!evaluations.length) return null;\n",
        "  const best = evaluations[0].score;\n",
        "  const tied = evaluations.filter(e => e.score === best);\n",
        "  return tied[Math.floor(Math.random() * tied.length)].action;\n",
        "}\n",
        "\n",
        "function randomTieEpisode(depthLimit, maxTurns=200){\n",
        "  let state = createInitialState();\n",
        "  let player = \"X\";\n",
        "  const history = new Set([getStateKey(state, player)]);\n",
        "  for(let turn=0; turn<maxTurns; turn++){\n",
        "    const w = getWinner(state);\n",
        "    if (w) return {winner:w, turns:turn};\n",
        "    if (isDraw(state)) return {winner:null, turns:turn};\n",
        "    const action = chooseWithRandomTiebreak(state, player, history, depthLimit);\n",
        "    if (!action) return {winner:null, turns:turn};\n",
        "    state = applyAction(state, action, player);\n",
        "    player = getOpponent(player);\n",
        "    history.add(getStateKey(state, player));\n",
        "  }\n",
        "  return {winner:\"timeout\", turns:maxTurns};\n",
        "}\n",
        "\n",
        "function randomTieSweep(depth, episodes){\n",
        "  const counts={X:0,O:0,draw:0,timeout:0};\n",
        "  for(let i=0;i<episodes;i++){\n",
        "    const r = randomTieEpisode(depth, 200);\n",
        "    if(r.winner===\"X\") counts.X++;\n",
        "    else if(r.winner===\"O\") counts.O++;\n",
        "    else if(r.winner===\"timeout\") counts.timeout++;\n",
        "    else counts.draw++;\n",
        "  }\n",
        "  return {depth, episodes, counts};\n",
        "}\n",
        "\n",
        "const out = {\n",
        "  deterministic: deterministicSweep(6),\n",
        "  random_tie_depth3: randomTieSweep(3, 100),\n",
        "  random_tie_depth4: randomTieSweep(4, 50)\n",
        "};\n",
        "\n",
        "console.log(JSON.stringify(out));\n",
        "\"\"\"\n",
        "\n",
        "analysis = json.loads(run_node(forced_win_js))\n",
        "analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3db8db2",
      "metadata": {},
      "source": [
        "### Practical conclusion so far\n",
        "\n",
        "- If you observe O wins at some depth/tie settings, then X is not established as a forced win by current evidence.\n",
        "- To prove forced win/loss/draw, you would need a full game-theoretic solve (retrograde or complete forward search with exact terminal values).\n",
        "- The sections above provide a reproducible path to tighten bounds and stress-test the hypothesis incrementally.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e043c243",
      "metadata": {},
      "source": [
        "## Tablebase Feasibility: Memory And Runtime Estimates\n",
        "\n",
        "This section estimates feasibility for a tablebase-style solve under different assumptions.\n",
        "\n",
        "Important caveat:\n",
        "- A classic tablebase assumes Markov state transitions.\n",
        "- Your repetition rule depends on full game history, so an exact solution for the current rules is not a plain tablebase.\n",
        "- The numbers below are best interpreted for a Markov approximation (state = board + active window + side-to-move).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b217a711",
      "metadata": {},
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "\n",
        "# State-count scenarios\n",
        "N_upper = 1_551_615_534  # combinatorial upper bound including side-to-move\n",
        "N_prefix_lower = 2_723_648  # exact reachable lower bound from depth-limited expansion to ply 8\n",
        "\n",
        "# Plausible solved-state fractions for scenario analysis\n",
        "fractions = [1.0, 0.5, 0.25, 0.10]\n",
        "\n",
        "def bytes_to_human(n: int) -> str:\n",
        "    units = [(1<<40, \"TiB\"), (1<<30, \"GiB\"), (1<<20, \"MiB\"), (1<<10, \"KiB\")]\n",
        "    for u, name in units:\n",
        "        if n >= u:\n",
        "            return f\"{n/u:.2f} {name}\"\n",
        "    return f\"{n} B\"\n",
        "\n",
        "def packed_bytes(states: int, bits_per_state: int) -> int:\n",
        "    return ceil(states * bits_per_state / 8)\n",
        "\n",
        "# Concrete encoding options\n",
        "encodings = [\n",
        "    (\"Outcome only (2 bits)\", 2),\n",
        "    (\"Outcome + DTW(8b) = 10 bits\", 10),\n",
        "    (\"Outcome + DTW(16b) = 18 bits\", 18),\n",
        "    (\"Outcome + best move(16b) = 18 bits\", 18),\n",
        "    (\"Outcome + DTW(8b) + best move(16b) = 26 bits\", 26),\n",
        "]\n",
        "\n",
        "rows = []\n",
        "for frac in fractions:\n",
        "    n = int(N_upper * frac)\n",
        "    for label, bits in encodings:\n",
        "        b = packed_bytes(n, bits)\n",
        "        rows.append((frac, n, label, bits, b, bytes_to_human(b)))\n",
        "\n",
        "for frac, n, label, bits, b, h in rows:\n",
        "    print(f\"fraction={frac:>4.0%} states={n:,} | {label:<42} | {bits:>2} bits/state | {h}\")\n",
        "\n",
        "print()\n",
        "print(\"Reference lower bound reached so far:\", f\"{N_prefix_lower:,}\", \"states\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10e92788",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Runtime estimates for retrograde-like passes over state records\n",
        "passes = [1, 3, 5]\n",
        "throughputs = [100_000, 500_000, 1_000_000, 5_000_000]  # states/sec\n",
        "\n",
        "def fmt_hours(hours: float) -> str:\n",
        "    if hours < 1:\n",
        "        return f\"{hours*60:.1f} min\"\n",
        "    if hours < 24:\n",
        "        return f\"{hours:.2f} h\"\n",
        "    return f\"{hours/24:.2f} d\"\n",
        "\n",
        "for frac in fractions:\n",
        "    n = int(N_upper * frac)\n",
        "    print()\n",
        "    print(f\"State fraction {frac:.0%} ({n:,} states):\")\n",
        "    for p in passes:\n",
        "        line = []\n",
        "        for t in throughputs:\n",
        "            hours = (n * p) / t / 3600\n",
        "            line.append(f\"{t:,}/s -> {fmt_hours(hours)}\")\n",
        "        print(f\"  passes={p}: \" + \" | \".join(line))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25988b9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# If you store explicit transitions (often unnecessary for retrograde), memory can dominate.\n",
        "# Estimate with average branching factor and 4-byte destination IDs.\n",
        "avg_branching = [8, 16, 24, 32]\n",
        "dest_bytes = 4\n",
        "\n",
        "for frac in fractions:\n",
        "    n = int(N_upper * frac)\n",
        "    print()\n",
        "    print(f\"Transition storage at fraction {frac:.0%} ({n:,} states):\")\n",
        "    for b in avg_branching:\n",
        "        bytes_needed = n * b * dest_bytes\n",
        "        print(f\"  avg branching={b:>2}: {bytes_to_human(bytes_needed)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10395954",
      "metadata": {},
      "source": [
        "### Readout\n",
        "\n",
        "- Memory for *value-only* storage is modest even near the upper bound (2 bits/state packed).\n",
        "- Runtime is likely the harder limit unless you parallelize and avoid storing full transition graphs.\n",
        "- For exact current rules (history-based repetition), expect a much harder problem than these numbers suggest.\n",
        "- A practical path is solving the Markov approximation first, then evaluating how often repetition-history changes move legality.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
